{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Dataset\n",
    "   - MNIST\n",
    "   - CIFAR 10\n",
    "   - CIFAR 100\n",
    " - choose architecture - MLP to classify the images of the datasets.\n",
    " - design 1 MLP for each dataset.\n",
    " - explore RELU, leakyRELU, sigmoid.\n",
    " - explore SGD, ADAM\n",
    " - explore cross entropy, mean squared loss\n",
    " - Include dropout, exclude dropout\n",
    "\n",
    "\n",
    "\n",
    " train each dataset it with relu with sgd, leaky relu with sgd then sigmoid with sgd.\n",
    " do the same relu with ADAM, leaky relu with ADAM then sigmoid with ADAM.\n",
    " use cross entropy for each case.\n",
    " for every model with relu and adam, use dropout.\n",
    " for other dont use dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer, output_size, activation_fn='relu', dropout_rate=0.0):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = []\n",
    "        prev = input_size\n",
    "        for hidden_size in hidden_layer:\n",
    "          self.layers.append(nn.Linear(prev, hidden_size))\n",
    "          self.layers.append(nn.BatchNorm1d(hidden_size))\n",
    "          self.layers.append(nn.ReLU())\n",
    "          self.layers.append(nn.Dropout(dropout_rate))\n",
    "          prev = hidden_size\n",
    "        self.layers.append(nn.Linear(prev, output_size))\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten input\n",
    "        return self.model(x)\n",
    "\n",
    "    def _apply_activation(self, x):\n",
    "        if self.activation_fn == 'relu':\n",
    "            return F.relu(x)\n",
    "        elif self.activation_fn == 'leaky_relu':\n",
    "            return F.leaky_relu(x, negative_slope=0.01)\n",
    "        elif self.activation_fn == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {self.activation_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_test_model(model, train_loader, test_loader, optimizer, criterion, epochs=10):\n",
    "    model.to(device)\n",
    "    train_losses, test_losses, test_accuracies = [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs} - Testing\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        test_losses.append(test_loss / len(test_loader))\n",
    "        test_accuracies.append(100 * correct / total)\n",
    "\n",
    "    return train_losses, test_losses, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(dataset_name):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)) if dataset_name == 'MNIST' else\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    if dataset_name == 'MNIST':\n",
    "        train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    elif dataset_name == 'CIFAR10':\n",
    "        train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    elif dataset_name == 'CIFAR100':\n",
    "        train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiments(dataset_name, input_size, output_size):\n",
    "    results = []\n",
    "    train_loader, test_loader = load_dataset(dataset_name)\n",
    "    if dataset_name == 'MNIST':\n",
    "      hidden_layer=[512, 256]\n",
    "    elif dataset_name == 'CIFAR10':\n",
    "      hidden_layer=[1024, 512, 256]\n",
    "    else:\n",
    "      hidden_layer=[1024, 512, 256, 128]\n",
    "    # Experiment 1: ReLU + SGD\n",
    "    model = MLP(input_size, hidden_layer, output_size, activation_fn='relu')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_losses, test_losses, test_accuracies = train_test_model(model, train_loader, test_loader, optimizer, criterion)\n",
    "    results.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Activation': 'ReLU',\n",
    "        'Optimizer': 'SGD',\n",
    "        'Dropout': 'No',\n",
    "        'Test Accuracy': max(test_accuracies)\n",
    "    })\n",
    "\n",
    "    # Experiment 2: Leaky ReLU + SGD\n",
    "    model = MLP(input_size, hidden_layer, output_size, activation_fn='leaky_relu')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_losses, test_losses, test_accuracies = train_test_model(model, train_loader, test_loader, optimizer, criterion)\n",
    "    results.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Activation': 'Leaky ReLU',\n",
    "        'Optimizer': 'SGD',\n",
    "        'Dropout': 'No',\n",
    "        'Test Accuracy': max(test_accuracies)\n",
    "    })\n",
    "\n",
    "    # Experiment 3: Sigmoid + SGD\n",
    "    model = MLP(input_size, hidden_layer, output_size, activation_fn='sigmoid')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_losses, test_losses, test_accuracies = train_test_model(model, train_loader, test_loader, optimizer, criterion)\n",
    "    results.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Activation': 'Sigmoid',\n",
    "        'Optimizer': 'SGD',\n",
    "        'Dropout': 'No',\n",
    "        'Test Accuracy': max(test_accuracies)\n",
    "    })\n",
    "\n",
    "    # Experiment 4: ReLU + ADAM\n",
    "    model = MLP(input_size, hidden_layer, output_size, activation_fn='relu')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_losses, test_losses, test_accuracies = train_test_model(model, train_loader, test_loader, optimizer, criterion)\n",
    "    results.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Activation': 'ReLU',\n",
    "        'Optimizer': 'ADAM',\n",
    "        'Dropout': 'No',\n",
    "        'Test Accuracy': max(test_accuracies)\n",
    "    })\n",
    "\n",
    "    # Experiment 5: ReLU + ADAM + Dropout\n",
    "    model = MLP(input_size, hidden_layer, output_size, activation_fn='relu', dropout_rate=0.3)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_losses, test_losses, test_accuracies = train_test_model(model, train_loader, test_loader, optimizer, criterion)\n",
    "    results.append({\n",
    "        'Dataset': dataset_name,\n",
    "        'Activation': 'ReLU',\n",
    "        'Optimizer': 'ADAM',\n",
    "        'Dropout': 'Yes',\n",
    "        'Test Accuracy': max(test_accuracies)\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments for MNIST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "Epoch 1/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 116.66it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 125.20it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 171.49it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 200.37it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 169.02it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 196.99it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 169.89it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 194.97it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 170.30it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 198.73it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 170.45it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 199.02it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 169.27it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 195.40it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 169.51it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 197.52it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 170.44it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 200.02it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 171.56it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 189.50it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 165.66it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 198.95it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 165.21it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 187.98it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 158.95it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 199.10it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 171.51it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 199.99it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 159.06it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 192.97it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 166.49it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 189.75it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 166.52it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 186.77it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 158.77it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 189.57it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 166.39it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 192.46it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 162.49it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 198.57it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 164.56it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 189.32it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 165.03it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 190.67it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 171.05it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 202.90it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 169.75it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 199.26it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 171.04it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 199.92it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 171.62it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 185.53it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 171.97it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 200.44it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 171.78it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 199.08it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 166.57it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 198.84it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 938/938 [00:05<00:00, 169.01it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 199.02it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 123.35it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 198.62it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 126.67it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 198.24it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 126.90it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 198.64it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 123.44it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 193.82it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 119.61it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 184.65it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 118.48it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 198.01it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 122.15it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 192.36it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 117.19it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 175.79it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 120.79it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 192.48it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 121.13it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 194.61it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 117.05it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 196.68it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 115.06it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 193.82it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 117.18it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 185.87it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 116.83it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 194.72it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 116.01it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 197.07it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 111.26it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 175.59it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 111.86it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 195.02it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 116.12it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 194.61it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 938/938 [00:08<00:00, 116.50it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 196.39it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 938/938 [00:07<00:00, 117.80it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:00<00:00, 195.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments for CIFAR10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 91.04it/s] \n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.37it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.74it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 138.97it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.54it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.36it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.99it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.72it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 100.92it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.30it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.24it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 131.82it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 92.69it/s] \n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.39it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:51<00:00, 15.11it/s] \n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 130.77it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 100.55it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.34it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.18it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.21it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.21it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.53it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.45it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.87it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.83it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.26it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.49it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.60it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.33it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.65it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.33it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.90it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.14it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.31it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.77it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.86it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 99.83it/s] \n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 127.66it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 94.76it/s] \n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 128.22it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 97.82it/s] \n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 138.32it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 100.13it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.92it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.98it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.97it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 102.46it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.11it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.95it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.01it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.99it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.19it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.38it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.31it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 95.30it/s] \n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 130.13it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 101.84it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.46it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 103.18it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 138.08it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 70.68it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 138.90it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.25it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.14it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 70.32it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.34it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.26it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 134.27it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.80it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 131.68it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.78it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 138.98it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 69.87it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 116.09it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 70.58it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 130.90it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 70.90it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.08it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 70.94it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.67it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 64.40it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.07it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 64.91it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.17it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 64.57it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.63it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 65.23it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.63it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 64.87it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.95it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 64.33it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 127.27it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 63.29it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.28it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 63.21it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 131.36it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 66.29it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 140.80it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 65.43it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments for CIFAR100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 90.70it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 129.95it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 99.23it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.99it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 94.82it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 117.65it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 96.20it/s] \n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.22it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.64it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 128.94it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 94.90it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.51it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 91.87it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.32it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 94.07it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 131.28it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 93.22it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.50it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 91.83it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 123.02it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 92.55it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.66it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 97.29it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.68it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.94it/s] \n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.34it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.40it/s] \n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.75it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.66it/s] \n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 138.12it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 99.04it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.81it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.70it/s] \n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.41it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.64it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.27it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.55it/s] \n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.42it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 97.85it/s] \n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.63it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.62it/s] \n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.25it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.87it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 138.41it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 93.11it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 136.03it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 96.54it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 131.30it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 97.91it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.40it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 97.20it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 134.68it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 97.54it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.08it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 97.80it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.87it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:08<00:00, 97.59it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 135.10it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:07<00:00, 98.33it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 131.85it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 67.40it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.09it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.49it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.84it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 69.05it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.86it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.30it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.86it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.64it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.17it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.58it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 134.58it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 68.63it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 106.97it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [01:45<00:00,  7.41it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 124.02it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [17:25<00:00,  1.34s/it]  \n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.77it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:11<00:00, 69.94it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 134.46it/s]\n",
      "Epoch 1/10 - Training: 100%|██████████| 782/782 [06:49<00:00,  1.91it/s]\n",
      "Epoch 1/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 106.33it/s]\n",
      "Epoch 2/10 - Training: 100%|██████████| 782/782 [00:13<00:00, 58.44it/s]\n",
      "Epoch 2/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 128.91it/s]\n",
      "Epoch 3/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 61.52it/s]\n",
      "Epoch 3/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 130.95it/s]\n",
      "Epoch 4/10 - Training: 100%|██████████| 782/782 [01:29<00:00,  8.72it/s]\n",
      "Epoch 4/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 137.87it/s]\n",
      "Epoch 5/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 61.75it/s]\n",
      "Epoch 5/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.27it/s]\n",
      "Epoch 6/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 62.43it/s]\n",
      "Epoch 6/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 134.33it/s]\n",
      "Epoch 7/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 62.42it/s]\n",
      "Epoch 7/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 133.69it/s]\n",
      "Epoch 8/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 61.08it/s]\n",
      "Epoch 8/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 132.36it/s]\n",
      "Epoch 9/10 - Training: 100%|██████████| 782/782 [00:13<00:00, 55.87it/s]\n",
      "Epoch 9/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 114.48it/s]\n",
      "Epoch 10/10 - Training: 100%|██████████| 782/782 [00:12<00:00, 61.45it/s]\n",
      "Epoch 10/10 - Testing: 100%|██████████| 157/157 [00:01<00:00, 134.87it/s]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mextend(results)\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_results)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperiment_results.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults saved to experiment_results.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/DL assignment/myenv/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DL assignment/myenv/lib/python3.13/site-packages/pandas/core/generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[1;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[1;32m   2407\u001b[0m     df,\n\u001b[1;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[1;32m   2416\u001b[0m )\n\u001b[0;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DL assignment/myenv/lib/python3.13/site-packages/pandas/io/formats/excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/DL assignment/myenv/lib/python3.13/site-packages/pandas/io/excel/_openpyxl.py:57\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     46\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m WriteExcelBuffer \u001b[38;5;241m|\u001b[39m ExcelWriter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[1;32m     59\u001b[0m     engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     62\u001b[0m         path,\n\u001b[1;32m     63\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m     67\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_s = [\n",
    "    ('MNIST', 28*28, 10),\n",
    "    ('CIFAR10', 32*32*3, 10),\n",
    "    ('CIFAR100', 32*32*3, 100)\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "for dataset_name, input_size, output_size in dataset_s:\n",
    "    print(f\"Running experiments for {dataset_name}...\")\n",
    "    results = run_experiments(dataset_name, input_size, output_size)\n",
    "    all_results.extend(results)\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "df.to_excel('experiment_results.xlsx', index=False)\n",
    "print(\"Results saved to experiment_results.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to experiment_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(all_results)\n",
    "df.to_excel('experiment_results.xlsx', index=False)\n",
    "print(\"Results saved to experiment_results.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
